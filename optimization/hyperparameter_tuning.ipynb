{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyN5QbsODF9y"
   },
   "source": [
    "# Introduction\n",
    "1. In this tutorial, we will be tuning hyperparameters for Stable baselines3 models using Optuna.\n",
    "2. The default model hyperparamters may not be adequate for your custom portfolio or custom state-space. Reinforcement learning algorithms are sensitive to hyperparamters, hence tuning is an important step.\n",
    "3. Hyperparamters are tuned based on an objective, which needs to be maximized or minimized. Here we tuned our hyperparamters to maximize the Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOFHove39LDW"
   },
   "outputs": [],
   "source": [
    "#Installing Optuna\n",
    "# %%capture\n",
    "# !pip3 install optuna\n",
    "# !pip install optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r8IfJOaf9ONk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import optuna\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/algorithmic_trading/CNN-DRL\")\n",
    "sys.path.append(\"/home/ubuntu/algorithmic_trading/CNN-DRL/FinRL-Meta\")\n",
    "\n",
    "from meta import config, config_tickers\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from meta.data_processor import DataProcessor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from agents2.agent import DRLAgent\n",
    "from envs.StockTradingEnvCNN import StockTradingEnvCNN\n",
    "from envs.StockTradingEnvMLP import StockTradingEnvMLP\n",
    "from policies.CnnPolicy import CustomCNN\n",
    "from plot2 import get_baseline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6WqG4qrD7mG"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v9dr04lLD7Gk"
   },
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = config.TRAIN_START_DATE\n",
    "TRAIN_END_DATE = config.TRAIN_END_DATE\n",
    "TEST_START_DATE = config.TEST_START_DATE\n",
    "TEST_END_DATE = config.TEST_END_DATE\n",
    "DOW_30_TICKER = config_tickers.DOW_30_TICKER\n",
    "INDICATORS = config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QhWBNtrJEALJ"
   },
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=30),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFze12XO6HCA"
   },
   "source": [
    "## Collecting data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1712466247599,
     "user": {
      "displayName": "윤기영",
      "userId": "15931879994433245025"
     },
     "user_tz": -540
    },
    "id": "XnYoEkCezoMY"
   },
   "outputs": [],
   "source": [
    "def instantiate_env(data_source, start_date, end_date, time_interval,\n",
    "                    ticker_list, technical_indicator_list, env,\n",
    "                    if_vix=True, cache=False, select_stockstats_talib=0,\n",
    "                    hmax=100, initial_amount=1000000, reward_scaling=1e-4,\n",
    "                    transaction_cost_pct=0.001, if_train=True, **kwargs):\n",
    "\n",
    "    # fetch data\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    DP = DataProcessor(\n",
    "        data_source=data_source,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        time_interval=time_interval\n",
    "    )\n",
    "    price_array, tech_array, turbulence_array = DP.run(\n",
    "        ticker_list=ticker_list,\n",
    "        technical_indicator_list=technical_indicator_list,\n",
    "        if_vix=if_vix,\n",
    "        cache=cache,\n",
    "        select_stockstats_talib=select_stockstats_talib\n",
    "    )\n",
    "\n",
    "    df = DP.dataframe\n",
    "    df = df.sort_values(['time', 'tic'], ignore_index=True)\n",
    "\n",
    "    stock_dimension = len(df.tic.unique())\n",
    "    state_space = 1 + 2*stock_dimension + len(technical_indicator_list)*stock_dimension\n",
    "\n",
    "    buy_cost_list = sell_cost_list = [transaction_cost_pct] * stock_dimension\n",
    "    num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "    env_kwargs = {\n",
    "        \"hmax\": hmax,\n",
    "        \"initial_amount\": initial_amount,\n",
    "        \"num_stock_shares\": num_stock_shares,\n",
    "        \"buy_cost_pct\": buy_cost_list,\n",
    "        \"sell_cost_pct\": sell_cost_list,\n",
    "        \"state_space\": state_space,\n",
    "        \"stock_dim\": stock_dimension,\n",
    "        \"tech_indicator_list\": technical_indicator_list,\n",
    "        \"action_space\": stock_dimension,\n",
    "        \"reward_scaling\": reward_scaling\n",
    "    }\n",
    "\n",
    "    if if_train:\n",
    "        e_train_gym = env(df=df, **env_kwargs)\n",
    "        agent = DRLAgent(env=e_train_gym)\n",
    "        return e_train_gym, agent\n",
    "    else:\n",
    "        e_trade_gym = env(df=df, turbulence_threshold=None, **env_kwargs)\n",
    "        return e_trade_gym, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HCZcjJK4Dwi8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yahoofinance successfully connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date       open       high        low      close  adjusted_close  \\\n",
      "0     2014-01-02  90.900002  91.080002  89.379997  89.449997       76.835388   \n",
      "1     2014-01-03  89.150002  90.080002  88.629997  89.739998       77.084503   \n",
      "2     2014-01-06  89.699997  90.250000  89.379997  89.699997       77.050117   \n",
      "3     2014-01-07  90.169998  90.699997  89.010002  89.360001       76.758095   \n",
      "4     2014-01-08  88.660004  89.639999  88.660004  89.410004       76.999229   \n",
      "...          ...        ...        ...        ...        ...             ...   \n",
      "48364 2020-07-24  42.820000  43.480000  42.299999  42.610001       35.357632   \n",
      "48365 2020-07-27  42.810001  44.480000  42.430000  44.000000       36.511047   \n",
      "48366 2020-07-28  43.740002  44.020000  42.590000  42.619999       35.365929   \n",
      "48367 2020-07-29  42.799999  43.636002  42.740002  43.520000       36.112736   \n",
      "48368 2020-07-30  42.660000  42.830002  41.340000  41.730000       34.627403   \n",
      "\n",
      "        volume  tic  day  \n",
      "0      5112000  AXP    3  \n",
      "1      3888500  AXP    4  \n",
      "2      2844700  AXP    0  \n",
      "3      4039500  AXP    1  \n",
      "4      3880200  AXP    2  \n",
      "...        ...  ...  ...  \n",
      "48364  2999600  DOW    4  \n",
      "48365  4733600  DOW    0  \n",
      "48366  3395400  DOW    1  \n",
      "48367  3186900  DOW    2  \n",
      "48368  4118700  DOW    3  \n",
      "\n",
      "[48369 rows x 9 columns]\n",
      "Shape of DataFrame:  (48369, 9)\n",
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (48369, 9)\n",
      "Clean data for AAPL\n",
      "Data clean for AAPL is finished.\n",
      "Clean data for AMGN\n",
      "Data clean for AMGN is finished.\n",
      "Clean data for AXP\n",
      "Data clean for AXP is finished.\n",
      "Clean data for BA\n",
      "Data clean for BA is finished.\n",
      "Clean data for CAT\n",
      "Data clean for CAT is finished.\n",
      "Clean data for CRM\n",
      "Data clean for CRM is finished.\n",
      "Clean data for CSCO\n",
      "Data clean for CSCO is finished.\n",
      "Clean data for CVX\n",
      "Data clean for CVX is finished.\n",
      "Clean data for DIS\n",
      "Data clean for DIS is finished.\n",
      "Clean data for DOW\n",
      "NaN data on start date, fill using first valid data.\n",
      "Data clean for DOW is finished.\n",
      "Clean data for GS\n",
      "Data clean for GS is finished.\n",
      "Clean data for HD\n",
      "Data clean for HD is finished.\n",
      "Clean data for HON\n",
      "Data clean for HON is finished.\n",
      "Clean data for IBM\n",
      "Data clean for IBM is finished.\n",
      "Clean data for INTC\n",
      "Data clean for INTC is finished.\n",
      "Clean data for JNJ\n",
      "Data clean for JNJ is finished.\n",
      "Clean data for JPM\n",
      "Data clean for JPM is finished.\n",
      "Clean data for KO\n",
      "Data clean for KO is finished.\n",
      "Clean data for MCD\n",
      "Data clean for MCD is finished.\n",
      "Clean data for MMM\n",
      "Data clean for MMM is finished.\n",
      "Clean data for MRK\n",
      "Data clean for MRK is finished.\n",
      "Clean data for MSFT\n",
      "Data clean for MSFT is finished.\n",
      "Clean data for NKE\n",
      "Data clean for NKE is finished.\n",
      "Clean data for PG\n",
      "Data clean for PG is finished.\n",
      "Clean data for TRV\n",
      "Data clean for TRV is finished.\n",
      "Clean data for UNH\n",
      "Data clean for UNH is finished.\n",
      "Clean data for V\n",
      "Data clean for V is finished.\n",
      "Clean data for VZ\n",
      "Data clean for VZ is finished.\n",
      "Clean data for WBA\n",
      "Data clean for WBA is finished.\n",
      "Clean data for WMT\n",
      "Data clean for WMT is finished.\n",
      "Data clean all finished!\n",
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date       open       high        low      close  adjusted_close  \\\n",
      "0    2014-01-02  14.320000  14.590000  14.000000  14.230000       14.230000   \n",
      "1    2014-01-03  14.060000  14.220000  13.570000  13.760000       13.760000   \n",
      "2    2014-01-06  13.410000  14.000000  13.220000  13.550000       13.550000   \n",
      "3    2014-01-07  12.380000  13.280000  12.160000  12.920000       12.920000   \n",
      "4    2014-01-08  13.040000  13.240000  12.860000  12.870000       12.870000   \n",
      "...         ...        ...        ...        ...        ...             ...   \n",
      "1651 2020-07-24  27.959999  28.580000  25.530001  25.840000       25.840000   \n",
      "1652 2020-07-27  26.600000  26.940001  24.549999  24.740000       24.740000   \n",
      "1653 2020-07-28  24.860001  25.850000  24.049999  25.440001       25.440001   \n",
      "1654 2020-07-29  25.160000  25.420000  23.730000  24.100000       24.100000   \n",
      "1655 2020-07-30  25.040001  28.290001  24.639999  24.760000       24.760000   \n",
      "\n",
      "      volume   tic  day  \n",
      "0          0  ^VIX    3  \n",
      "1          0  ^VIX    4  \n",
      "2          0  ^VIX    0  \n",
      "3          0  ^VIX    1  \n",
      "4          0  ^VIX    2  \n",
      "...      ...   ...  ...  \n",
      "1651       0  ^VIX    4  \n",
      "1652       0  ^VIX    0  \n",
      "1653       0  ^VIX    1  \n",
      "1654       0  ^VIX    2  \n",
      "1655       0  ^VIX    3  \n",
      "\n",
      "[1656 rows x 9 columns]\n",
      "Shape of DataFrame:  (1656, 9)\n",
      "Download complete! Dataset saved to ./data/vix.csv. \n",
      "Shape of DataFrame: (1656, 9)\n",
      "Clean data for ^VIX\n",
      "Data clean for ^VIX is finished.\n",
      "Data clean all finished!\n",
      "Successfully transformed into array\n",
      "yahoofinance successfully connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date       open       high        low      close  adjusted_close  \\\n",
      "0    2020-08-03  93.309998  94.400002  92.440002  93.540001       89.009560   \n",
      "1    2020-08-04  93.489998  93.800003  92.489998  93.190002       88.676506   \n",
      "2    2020-08-05  93.820000  95.580002  93.809998  95.389999       90.769951   \n",
      "3    2020-08-06  95.180000  96.269997  94.480003  95.919998       91.274269   \n",
      "4    2020-08-07  95.290001  99.300003  94.949997  99.160004       94.357353   \n",
      "...         ...        ...        ...        ...        ...             ...   \n",
      "8815 2021-09-24  57.200001  57.340000  56.740002  56.810001       50.040340   \n",
      "8816 2021-09-27  56.880001  60.380001  56.880001  59.689999       52.577145   \n",
      "8817 2021-09-28  60.150002  60.645000  59.139999  59.459999       52.374550   \n",
      "8818 2021-09-29  59.459999  59.599998  58.770000  58.820000       51.810814   \n",
      "8819 2021-09-30  58.919998  59.169998  57.549999  57.560001       50.700966   \n",
      "\n",
      "        volume  tic  day  \n",
      "0      2869000  AXP    0  \n",
      "1      2415100  AXP    1  \n",
      "2      2844900  AXP    2  \n",
      "3      2698800  AXP    3  \n",
      "4      4690700  AXP    4  \n",
      "...        ...  ...  ...  \n",
      "8815   7964900  DOW    4  \n",
      "8816  12374000  DOW    0  \n",
      "8817   6681800  DOW    1  \n",
      "8818   4578800  DOW    2  \n",
      "8819   4929000  DOW    3  \n",
      "\n",
      "[8820 rows x 9 columns]\n",
      "Shape of DataFrame:  (8820, 9)\n",
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (8820, 9)\n",
      "Clean data for AAPL\n",
      "Data clean for AAPL is finished.\n",
      "Clean data for AMGN\n",
      "Data clean for AMGN is finished.\n",
      "Clean data for AXP\n",
      "Data clean for AXP is finished.\n",
      "Clean data for BA\n",
      "Data clean for BA is finished.\n",
      "Clean data for CAT\n",
      "Data clean for CAT is finished.\n",
      "Clean data for CRM\n",
      "Data clean for CRM is finished.\n",
      "Clean data for CSCO\n",
      "Data clean for CSCO is finished.\n",
      "Clean data for CVX\n",
      "Data clean for CVX is finished.\n",
      "Clean data for DIS\n",
      "Data clean for DIS is finished.\n",
      "Clean data for DOW\n",
      "Data clean for DOW is finished.\n",
      "Clean data for GS\n",
      "Data clean for GS is finished.\n",
      "Clean data for HD\n",
      "Data clean for HD is finished.\n",
      "Clean data for HON\n",
      "Data clean for HON is finished.\n",
      "Clean data for IBM\n",
      "Data clean for IBM is finished.\n",
      "Clean data for INTC\n",
      "Data clean for INTC is finished.\n",
      "Clean data for JNJ\n",
      "Data clean for JNJ is finished.\n",
      "Clean data for JPM\n",
      "Data clean for JPM is finished.\n",
      "Clean data for KO\n",
      "Data clean for KO is finished.\n",
      "Clean data for MCD\n",
      "Data clean for MCD is finished.\n",
      "Clean data for MMM\n",
      "Data clean for MMM is finished.\n",
      "Clean data for MRK\n",
      "Data clean for MRK is finished.\n",
      "Clean data for MSFT\n",
      "Data clean for MSFT is finished.\n",
      "Clean data for NKE\n",
      "Data clean for NKE is finished.\n",
      "Clean data for PG\n",
      "Data clean for PG is finished.\n",
      "Clean data for TRV\n",
      "Data clean for TRV is finished.\n",
      "Clean data for UNH\n",
      "Data clean for UNH is finished.\n",
      "Clean data for V\n",
      "Data clean for V is finished.\n",
      "Clean data for VZ\n",
      "Data clean for VZ is finished.\n",
      "Clean data for WBA\n",
      "Data clean for WBA is finished.\n",
      "Clean data for WMT\n",
      "Data clean for WMT is finished.\n",
      "Data clean all finished!\n",
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully add technical indicators\n",
      "          date       open       high        low      close  adjusted_close  \\\n",
      "0   2020-08-03  25.750000  26.010000  22.170000  24.280001       24.280001   \n",
      "1   2020-08-04  24.010000  24.760000  22.920000  23.760000       23.760000   \n",
      "2   2020-08-05  23.440001  23.610001  22.860001  22.990000       22.990000   \n",
      "3   2020-08-06  23.030001  24.110001  20.969999  22.650000       22.650000   \n",
      "4   2020-08-07  23.450001  24.020000  22.020000  22.209999       22.209999   \n",
      "..         ...        ...        ...        ...        ...             ...   \n",
      "289 2021-09-24  19.330000  20.410000  17.629999  17.750000       17.750000   \n",
      "290 2021-09-27  17.780001  19.320000  17.740000  18.760000       18.760000   \n",
      "291 2021-09-28  19.740000  24.820000  19.709999  23.250000       23.250000   \n",
      "292 2021-09-29  22.070000  23.790001  21.450001  22.559999       22.559999   \n",
      "293 2021-09-30  21.480000  24.709999  20.600000  23.139999       23.139999   \n",
      "\n",
      "     volume   tic  day  \n",
      "0         0  ^VIX    0  \n",
      "1         0  ^VIX    1  \n",
      "2         0  ^VIX    2  \n",
      "3         0  ^VIX    3  \n",
      "4         0  ^VIX    4  \n",
      "..      ...   ...  ...  \n",
      "289       0  ^VIX    4  \n",
      "290       0  ^VIX    0  \n",
      "291       0  ^VIX    1  \n",
      "292       0  ^VIX    2  \n",
      "293       0  ^VIX    3  \n",
      "\n",
      "[294 rows x 9 columns]\n",
      "Shape of DataFrame:  (294, 9)\n",
      "Download complete! Dataset saved to ./data/vix.csv. \n",
      "Shape of DataFrame: (294, 9)\n",
      "Clean data for ^VIX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data clean for ^VIX is finished.\n",
      "Data clean all finished!\n",
      "Successfully transformed into array\n"
     ]
    }
   ],
   "source": [
    "e_train_gym, agent = instantiate_env(start_date=TRAIN_START_DATE,\n",
    "                                    end_date=TRAIN_END_DATE,\n",
    "                                    ticker_list=DOW_30_TICKER,\n",
    "                                    data_source='yahoofinance',\n",
    "                                    time_interval='1D',\n",
    "                                    technical_indicator_list=INDICATORS,\n",
    "                                    env=StockTradingEnvCNN)\n",
    "\n",
    "e_trade_gym, _ = instantiate_env(start_date=TEST_START_DATE,\n",
    "                                end_date=TEST_END_DATE,\n",
    "                                ticker_list=DOW_30_TICKER,\n",
    "                                data_source='yahoofinance',\n",
    "                                time_interval='1D',\n",
    "                                technical_indicator_list=INDICATORS,\n",
    "                                env=StockTradingEnvCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvtd1jIY54fs"
   },
   "source": [
    "## Tuning hyperparameters using Optuna\n",
    "1. Go to this [link](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/utils/hyperparams_opt.py), you will find all possible hyperparamters to tune for all the models.\n",
    "2. For your model, grab those hyperparamters which you want to optimize and then return a dictionary of hyperparamters.\n",
    "3. There is a feature in Optuna called as hyperparamters importance, you can point out those hyperparamters which are important for tuning.\n",
    "4. By default Optuna use [TPESampler](https://www.youtube.com/watch?v=tdwgR1AqQ8Y) for sampling hyperparamters from the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WgmdCD2y5bgO"
   },
   "outputs": [],
   "source": [
    "def sample_ddpg_params(trial:optuna.Trial):\n",
    "    # Size of the replay buffer\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(3e4), int(5e4)])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    \n",
    "    return {\"buffer_size\": buffer_size,\n",
    "          \"learning_rate\":learning_rate,\n",
    "          \"batch_size\":batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TFidKG085dn3"
   },
   "outputs": [],
   "source": [
    "#Calculate the Sharpe ratio\n",
    "#This is our objective for tuning\n",
    "def calculate_sharpe(df):\n",
    "    df['daily_return'] = df['account_value'].pct_change(1)\n",
    "    if df['daily_return'].std() !=0:\n",
    "        sharpe = (252**0.5)*df['daily_return'].mean()/ \\\n",
    "              df['daily_return'].std()\n",
    "        return sharpe\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVNemrFf5i-D"
   },
   "source": [
    "## Callbacks\n",
    "1. The callback will terminate if the improvement margin is below certain point\n",
    "2. It will terminate after certain number of trial_number are reached, not before that\n",
    "3. It will hold its patience to reach the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6jufHQeh5jfb"
   },
   "outputs": [],
   "source": [
    "class LoggingCallback:\n",
    "    def __init__(self,threshold,trial_number,patience):\n",
    "        '''\n",
    "        threshold:int tolerance for increase in sharpe ratio\n",
    "        trial_number: int Prune after minimum number of trials\n",
    "        patience: int patience for the threshold\n",
    "        '''\n",
    "        self.threshold = threshold\n",
    "        self.trial_number  = trial_number\n",
    "        self.patience = patience\n",
    "        self.cb_list = [] #Trials list for which threshold is reached\n",
    "    def __call__(self,study:optuna.study, frozen_trial:optuna.Trial):\n",
    "        #Setting the best value in the current trial\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        \n",
    "        #Checking if the minimum number of trials have pass\n",
    "        if frozen_trial.number >self.trial_number:\n",
    "            previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
    "            #Checking if the previous and current objective values have the same sign\n",
    "            if previous_best_value * study.best_value >=0:\n",
    "                #Checking for the threshold condition\n",
    "                if abs(previous_best_value-study.best_value) < self.threshold:\n",
    "                    self.cb_list.append(frozen_trial.number)\n",
    "                    #If threshold is achieved for the patience amount of time\n",
    "                    if len(self.cb_list)>self.patience:\n",
    "                        print('The study stops now...')\n",
    "                        print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
    "                        print('The previous and current best values are {} and {} respectively'\n",
    "                              .format(previous_best_value, study.best_value))\n",
    "                        study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kS9MFCgh5oFH"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\",exist_ok=True)\n",
    "\n",
    "def objective(trial:optuna.Trial, model_name, policy, sample_model_params, policy_kwargs, total_timesteps):\n",
    "    #Trial will suggest a set of hyperparamters from the specified range\n",
    "    hyperparameters = sample_model_params(trial)\n",
    "    model = agent.get_model(model_name, policy=policy, model_kwargs = hyperparameters, policy_kwargs=policy_kwargs)\n",
    "    #You can increase it for better comparison\n",
    "    trained_model = agent.train_model(model=model,\n",
    "                                  tb_log_name=model_name,\n",
    "                                  total_timesteps=total_timesteps)\n",
    "    trained_model.save(f'models/{model_name}_{trial.number}.pth')\n",
    "    clear_output(wait=True)\n",
    "    #For the given hyperparamters, determine the account value in the trading period\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_model,\n",
    "    environment = e_trade_gym)\n",
    "    #Calculate sharpe from the account value\n",
    "    sharpe = calculate_sharpe(df_account_value)\n",
    "    \n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a study object and specify the direction as 'maximize'\n",
    "#As you want to maximize sharpe\n",
    "#Pruner stops not promising iterations\n",
    "#Use a pruner, else you will get error related to divergence of model\n",
    "#You can also use Multivariate samplere\n",
    "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
    "# Sampler using TPE (Tree-structured Parzen Estimator) algorithm\n",
    "def run_paramtune(**kwargs):\n",
    "    model_name = kwargs.get('model_name')\n",
    "    policy = kwargs.get('policy', 'MlpPolicy')\n",
    "    sample_model_params = kwargs.get('sample_model_params')\n",
    "    policy_kwargs = kwargs.get('policy_kwargs', None)\n",
    "    n_trials = kwargs.get('n_trials', 30)\n",
    "    total_timesteps = kwargs.get('total_timesteps', 10000)\n",
    "    \n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(study_name=f\"{model_name}_study\",direction='maximize',\n",
    "                                sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
    "    \n",
    "    logging_callback = LoggingCallback(threshold=1e-5,patience=30,trial_number=5)\n",
    "    #You can increase the n_trials for a better search space scanning\n",
    "    study.optimize(lambda trial: objective(trial, model_name, policy, sample_model_params, policy_kwargs, total_timesteps),\n",
    "                   n_trials=n_trials, catch=(ValueError,),callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-08 10:36:39,709] A new study created in memory with name: ddpg_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'buffer_size': 30000, 'learning_rate': 0.0006251373574521745, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to tensorboard_log/ddpg/ddpg_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 8.63     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 1024     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.38    |\n",
      "|    critic_loss     | 3.68     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 923      |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 345, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1176765.43\n",
      "total_reward: 176765.43\n",
      "total_cost: 132.41\n",
      "total_trades: 3324\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 3.41     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 2048     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.3    |\n",
      "|    critic_loss     | 1.74     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 1947     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 2.27     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 3072     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.4    |\n",
      "|    critic_loss     | 1.01     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 2971     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 345, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1101885.06\n",
      "total_reward: 101885.06\n",
      "total_cost: 0.00\n",
      "total_trades: 4080\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 1.7      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 4096     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.8    |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 3995     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 1.36     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 5120     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.43    |\n",
      "|    critic_loss     | 1.06     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 5019     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 1.14     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 6144     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.67    |\n",
      "|    critic_loss     | 0.192    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 6043     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 345, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1101885.06\n",
      "total_reward: 101885.06\n",
      "total_cost: 0.00\n",
      "total_trades: 4335\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.973    |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 7168     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.7     |\n",
      "|    critic_loss     | 0.131    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 7067     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.851    |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 8192     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.72    |\n",
      "|    critic_loss     | 0.146    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 8091     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 345, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1101885.06\n",
      "total_reward: 101885.06\n",
      "total_cost: 0.00\n",
      "total_trades: 4080\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.757    |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 9216     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.41    |\n",
      "|    critic_loss     | 1.25     |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 9115     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.681    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 10240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.19    |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 10139    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.619    |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 11264    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.68    |\n",
      "|    critic_loss     | 0.132    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 11163    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 345, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1101885.06\n",
      "total_reward: 101885.06\n",
      "total_cost: 0.00\n",
      "total_trades: 3825\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 0.568    |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 283      |\n",
      "|    total_timesteps | 12288    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.52    |\n",
      "|    critic_loss     | 0.151    |\n",
      "|    learning_rate   | 0.000625 |\n",
      "|    n_updates       | 12187    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-04-08 10:41:35,671] Trial 0 failed with parameters: {'buffer_size': 30000, 'learning_rate': 0.0006251373574521745, 'batch_size': 64} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2574/2567411073.py\", line 22, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, model_name, policy, sample_model_params, policy_kwargs, total_timesteps),\n",
      "  File \"/tmp/ipykernel_2574/3004778151.py\", line 12, in objective\n",
      "    trained_model = agent.train_model(model=model,\n",
      "  File \"/home/ubuntu/algorithmic_trading/CNN-DRL/agents2/agent.py\", line 107, in train_model\n",
      "    model = model.learn(\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py\", line 123, in learn\n",
      "    return super().learn(\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\", line 222, in learn\n",
      "    return super().learn(\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 328, in learn\n",
      "    rollout = self.collect_rollouts(\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 557, in collect_rollouts\n",
      "    actions, buffer_actions = self._sample_action(learning_starts, action_noise, env.num_envs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\", line 390, in _sample_action\n",
      "    unscaled_action, _ = self.predict(self._last_obs, deterministic=False)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/base_class.py\", line 556, in predict\n",
      "    return self.policy.predict(observation, state, episode_start, deterministic)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/policies.py\", line 368, in predict\n",
      "    actions = self._predict(obs_tensor, deterministic=deterministic)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/policies.py\", line 242, in _predict\n",
      "    return self.actor(observation)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/policies.py\", line 77, in forward\n",
      "    features = self.extract_features(obs, self.features_extractor)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/policies.py\", line 131, in extract_features\n",
      "    return features_extractor(preprocessed_obs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/algorithmic_trading/CNN-DRL/policies/CnnPolicy.py\", line 41, in forward\n",
      "    return self.linear(self.cnn(observations))\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/ubuntu/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n",
      "[W 2024-04-08 10:41:35,680] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_paramtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mddpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCnnPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43msample_model_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_ddpg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mrun_paramtune\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m logging_callback \u001b[38;5;241m=\u001b[39m LoggingCallback(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,trial_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#You can increase the n_trials for a better search space scanning\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlogging_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mrun_paramtune.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m logging_callback \u001b[38;5;241m=\u001b[39m LoggingCallback(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,trial_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#You can increase the n_trials for a better search space scanning\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     23\u001b[0m                n_trials\u001b[38;5;241m=\u001b[39mn_trials, catch\u001b[38;5;241m=\u001b[39m(\u001b[38;5;167;01mValueError\u001b[39;00m,),callbacks\u001b[38;5;241m=\u001b[39m[logging_callback])\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, model_name, policy, sample_model_params, policy_kwargs, total_timesteps)\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_model(model_name, policy\u001b[38;5;241m=\u001b[39mpolicy, model_kwargs \u001b[38;5;241m=\u001b[39m hyperparameters, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#You can increase it for better comparison\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m trained_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/algorithmic_trading/CNN-DRL/agents2/agent.py:107\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m--> 107\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:557\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mreset_noise(env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# Select action randomly or according to policy\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m    560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:390\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._sample_action\u001b[0;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# Note: when using continuous actions,\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself._last_obs was not set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 390\u001b[0m     unscaled_action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[1;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/policies.py:242\u001b[0m, in \u001b[0;36mTD3Policy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Note: the deterministic deterministic parameter is ignored in the case of TD3.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#   Predictions are always deterministic.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/td3/policies.py:77\u001b[0m, in \u001b[0;36mActor.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# assert deterministic, 'The TD3 actor only outputs deterministic actions'\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu(features)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/algorithmic_trading/CNN-DRL/policies/CnnPolicy.py:41\u001b[0m, in \u001b[0;36mCustomCNN.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_paramtune(model_name=\"ddpg\",\n",
    "              policy=\"CnnPolicy\",\n",
    "              sample_model_params=sample_ddpg_params,\n",
    "              policy_kwargs=policy_kwargs,\n",
    "              n_trials=10,\n",
    "              total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZ1UKe9Y-rDm"
   },
   "outputs": [],
   "source": [
    "joblib.dump(study, \"final_ddpg_study__.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cY8SaBX-sz9"
   },
   "outputs": [],
   "source": [
    "#Get the best hyperparamters\n",
    "print('Hyperparameters after tuning',study.best_params)\n",
    "print('Hyperparameters before tuning',config.DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5bgBAK8-zed"
   },
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcOVRADC-2xy"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=e_train_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UyIuUlb-4fh"
   },
   "outputs": [],
   "source": [
    "#Trading period account value with tuned model\n",
    "df_account_value_tuned, df_actions_tuned = DRLAgent.DRL_prediction(\n",
    "    model=tuned_model_ddpg,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EF8MNnpJ_PPM"
   },
   "outputs": [],
   "source": [
    "#Backtesting with our pruned model\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_tuned = backtest_stats(account_value=df_account_value_tuned)\n",
    "perf_stats_all_tuned = pd.DataFrame(perf_stats_all_tuned)\n",
    "perf_stats_all_tuned.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_tuned_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lz-OLzba_TPb"
   },
   "outputs": [],
   "source": [
    "#Now train with not tuned hyperaparameters\n",
    "#Default config.ddpg_PARAMS\n",
    "non_tuned_model_ddpg = agent.get_model(\"ddpg\",model_kwargs = config.DDPG_PARAMS )\n",
    "trained_ddpg = agent.train_model(model=non_tuned_model_ddpg,\n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00few2j7_XpW"
   },
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw96GawH_YVv"
   },
   "outputs": [],
   "source": [
    "#Backtesting for not tuned hyperparamters\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "# perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfbgJDpM_Z53"
   },
   "outputs": [],
   "source": [
    "#You can see with trial, our sharpe ratio is increasing\n",
    "#Certainly you can afford more number of trials for further optimization\n",
    "from optuna.visualization import plot_optimization_history\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Rn_yRTu_dAB"
   },
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjA4K8rB_enC"
   },
   "outputs": [],
   "source": [
    "#Hyperparamters importance\n",
    "#Ent_coef is the most important\n",
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkCxS80B_jrh"
   },
   "source": [
    "## Further works\n",
    "\n",
    "1.   You can tune more critical hyperparameters\n",
    "2.   Multi-objective hyperparameter optimization using Optuna. Here we can maximize Sharpe and simultaneously minimize Volatility in our account value to tune our hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WN_20M_3_kD8"
   },
   "outputs": [],
   "source": [
    "plot_edf(study)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8RH/aVXoct9ta4qbWBmOF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
